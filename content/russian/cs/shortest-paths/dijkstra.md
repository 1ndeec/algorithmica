---
title: Алгоритм Дейкстры
authors:
- Максим Иванов
weight: 3
---

Заведём массив d[], в котором для каждой вершины v будем хранить текущую длину d[v] кратчайшего пути из s в v. Изначально d[s]=0, а для всех остальных вершин эта длина равна бесконечности (при реализации на компьютере обычно в качестве бесконечности выбирают просто достаточно большое число, заведомо большее возможной длины пути):

 d[v] = \infty, v \ne s 

Кроме того, для каждой вершины v будем хранить, помечена она ещё или нет, т.е. заведём булевский массив u[]. Изначально все вершины не помечены, т.е.

 u[v] = {\rm false} 

Сам алгоритм Дейкстры состоит из n итераций. На очередной итерации выбирается вершина v с наименьшей величиной d[v] среди ещё не помеченных, т.е.:

 d[v] = \min_{p:\ u[p]={\rm false}} d[p] 

(Понятно, что на первой итерации выбрана будет стартовая вершина s.)

Выбранная таким образом вершина v отмечается помеченной. Далее, на текущей итерации, из вершины v производятся релаксации: просматриваются все рёбра (v,to), исходящие из вершины v, и для каждой такой вершины to алгоритм пытается улучшить значение d[to]. Пусть длина текущего ребра равна \rm len, тогда в виде кода релаксация выглядит как:

 d[to] = \min (d[to], d[v] + {\rm len}) 

На этом текущая итерация заканчивается, алгоритм переходит к следующей итерации (снова выбирается вершина с наименьшей величиной d, из неё производятся релаксации, и т.д.). При этом в конце концов, после n итераций, все вершины графа станут помеченными, и алгоритм свою работу завершает. Утверждается, что найденные значения d[v] и есть искомые длины кратчайших путей из s в v.

Стоит заметить, что, если не все вершины графа достижимы из вершины s, то значения d[v] для них так и останутся бесконечными. Понятно, что несколько последних итераций алгоритма будут как раз выбирать эти вершины, но никакой полезной работы производить эти итерации не будут (поскольку бесконечное расстояние не сможет прорелаксировать другие, даже тоже бесконечные расстояния). Поэтому алгоритм можно сразу останавливать, как только в качестве выбранной вершины берётся вершина с бесконечным расстоянием.

Восстановление путей. Разумеется, обычно нужно знать не только длины кратчайших путей, но и получить сами пути. Покажем, как сохранить информацию, достаточную для последующего восстановления кратчайшего пути из s до любой вершины. Для этого достаточно так называемого массива предков: массива p[], в котором для каждой вершины v \ne s хранится номер вершины p[v], являющейся предпоследней в кратчайшем пути до вершины v. Здесь используется тот факт, что если мы возьмём кратчайший путь до какой-то вершины v, а затем удалим из этого пути последнюю вершину, то получится путь, оканчивающийся некоторой вершиной p[v], и этот путь будет кратчайшим для вершины p[v]. Итак, если мы будем обладать этим массивом предков, то кратчайший путь можно будет восстановить по нему, просто каждый раз беря предка от текущей вершины, пока мы не придём в стартовую вершину s — так мы получим искомый кратчайший путь, но записанный в обратном порядке. Итак, кратчайший путь P до вершины v равен:

 P = (s, \ldots, p[p[p[v]]], p[p[v]], p[v], v) 

Осталось понять, как строить этот массив предков. Однако это делается очень просто: при каждой успешной релаксации, т.е. когда из выбранной вершины v происходит улучшение расстояния до некоторой вершины to, мы записываем, что предком вершины to является вершина v:

 p[to] = v 

Доказательство
Основное утверждение, на котором основана корректность алгоритма Дейкстры, следующее. Утверждается, что после того как какая-либо вершина v становится помеченной, текущее расстояние до неё d[v] уже является кратчайшим, и, соответственно, больше меняться не будет.

Доказательство будем производить по индукции. Для первой итерации справедливость его очевидна — для вершины s имеем d[s]=0, что и является длиной кратчайшего пути до неё. Пусть теперь это утверждение выполнено для всех предыдущих итераций, т.е. всех уже помеченных вершин; докажем, что оно не нарушается после выполнения текущей итерации. Пусть v — вершина, выбранная на текущей итерации, т.е. вершина, которую алгоритм собирается пометить. Докажем, что d[v] действительно равно длине кратчайшего пути до неё (обозначим эту длину через l[v]).

Рассмотрим кратчайший путь P до вершины v. Понятно, этот путь можно разбить на два пути: P_1, состоящий только из помеченных вершин (как минимум стартовая вершина s будет в этом пути), и остальная часть пути P_2 (она тоже может включать помеченные вершины, но начинается обязательно с непомеченной). Обозначим через p первую вершину пути P_2, а через q — последнюю вершины пути P_1.

Докажем сначала наше утверждение для вершины p, т.е. докажем равенство d[p] = l[p]. Однако это практически очевидно: ведь на одной из предыдущих итераций мы выбирали вершину q и выполняли релаксацию из неё. Поскольку (в силу самого выбора вершины p) кратчайший путь до p равен кратчайшему пути до q плюс ребро (p,q), то при выполнении релаксации из q величина d[p] действительно установится в требуемое значение.

Вследствие неотрицательности стоимостей рёбер длина кратчайшего пути l[p] (а она по только что доказанному равна d[p]) не превосходит длины l[v] кратчайшего пути до вершины v. Учитывая, что l[v] \le d[v] (ведь алгоритм Дейкстры не мог найти более короткого пути, чем это вообще возможно), в итоге получаем соотношения:

 d[p] = l[p] \le l[v] \le d[v] 

С другой стороны, поскольку и p, и v — вершины непомеченные, то так как на текущей итерации была выбрана именно вершина v, а не вершина p, то получаем другое неравенство:

 d[p] \ge d[v] 

Из этих двух неравенств заключаем равенство d[p] = d[v], а тогда из найденных до этого соотношений получаем и:

 d[v] = l[v] 

что и требовалось доказать.

Реализация
Итак, алгоритм Дейкстры представляет собой n итераций, на каждой из которых выбирается непомеченная вершина с наименьшей величиной d[v], эта вершина помечается, и затем просматриваются все рёбра, исходящие из данной вершины, и вдоль каждого ребра делается попытка улучшить значение d[] на другом конце ребра.

Время работы алгоритма складывается из:

n раз поиск вершины с наименьшей величиной d[v] среди всех непомеченных вершин, т.е. среди O(n) вершин
m раз производится попытка релаксаций
При простейшей реализации этих операций на поиск вершины будет затрачиваться O(n) операций, а на одну релаксацию — O(1) операций, и итоговая асимптотика алгоритма составляет:

 O(n^2+m) 

Реализация:

const int INF = 1000000000;
 
int main() {
	int n;
	... чтение n ...
	vector < vector < pair<int,int> > > g (n);
	... чтение графа ...
	int s = ...; // стартовая вершина
 
	vector<int> d (n, INF),  p (n);
	d[s] = 0;
	vector<char> u (n);
	for (int i=0; i<n; ++i) {
		int v = -1;
		for (int j=0; j<n; ++j)
			if (!u[j] && (v == -1 || d[j] < d[v]))
				v = j;
		if (d[v] == INF)
			break;
		u[v] = true;
 
		for (size_t j=0; j<g[v].size(); ++j) {
			int to = g[v][j].first,
				len = g[v][j].second;
			if (d[v] + len < d[to]) {
				d[to] = d[v] + len;
				p[to] = v;
			}
		}
	}
}
Здесь граф g хранится в виде списков смежности: для каждой вершины v список g[v] содержит список рёбер, исходящих из этой вершины, т.е. список пар \rm pair<int,int>, где первый элемент пары — вершина, в которую ведёт ребро, а второй элемент — вес ребра.

После чтения заводятся массивы расстояний d[], меток u[] и предков p[]. Затем выполняются n итераций. На каждой итерации сначала находится вершина v, имеющая наименьшее расстояние d[] среди непомеченных вершин. Если расстояние до выбранной вершины v оказывается равным бесконечности, то алгоритм останавливается. Иначе вершина помечается как помеченная, и просматриваются все рёбра, исходящие из данной вершины, и вдоль каждого ребра выполняются релаксации. Если релаксация успешна (т.е. расстояние d[to] меняется), то пересчитывается расстояние d[to] и сохраняется предок p[].

После выполнения всех итераций в массиве d[] оказываются длины кратчайших путей до всех вершин, а в массиве p[] — предки всех вершин (кроме стартовой s). Восстановить путь до любой вершины t можно следующим образом:

vector<int> path;
for (int v=t; v!=s; v=p[v])
	path.push_back (v);
path.push_back (s);
reverse (path.begin(), path.end());

## Алгоритм за $O(m \log n)$

Напомним, что сложность алгоритма Дейкстры складывается из двух основных операций: время нахождения вершины с наименьшей величиной расстояния d[v], и время совершения релаксации, т.е. время изменения величины d[to].

При простейшей реализации эти операции потребуют соответственно O(n) и O(1) времени. Учитывая, что первая операция всего выполняется O(n) раз, а вторая — O(m), получаем асимптотику простейшей реализации алгоритма Дейкстры: O(n^2+m).

Понятно, что эта асимптотика является оптимальной для плотных графов, т.е. когда m \approx n^2. Чем более разрежен граф (т.е. чем меньше m по сравнению с максимальным количество рёбер n^2), тем менее оптимальной становится эта оценка, и по вине первого слагаемого. Таким образом, надо улучшать время выполнения операций первого типа, не сильно ухудшая при этом время выполнения операций второго типа.

Для этого надо использовать различные вспомогательные структуры данных. Наиболее привлекательными являются Фибоначчиевы кучи, которые позволяют производить операцию первого вида за O(\log n), а второго — за O(1). Поэтому при использовании Фибоначчиевых куч время работы алгоритма Дейкстры составит O(n \log n + m), что является практически теоретическим минимумом для алгоритма поиска кратчайшего пути. Кстати говоря, эта оценка является оптимальной для алгоритмов, основанных на алгоритме Дейкстры, т.е. Фибоначчиевы кучи являются оптимальными с этой точки зрения (это утверждение об оптимальности на самом деле основано на невозможности существования такой "идеальной" структуры данных — если бы она существовала, то можно было бы выполнять сортировку за линейное время, что, как известно, в общем случае невозможно; впрочем, интересно, что существует алгоритм Торупа (Thorup), который ищет кратчайший путь с оптимальной, линейной, асимптотикой, но основан он на совсем другой идее, чем алгоритм Дейкстры, поэтому никакого противоречия здесь нет). Однако, Фибоначчиевы кучи довольно сложны в реализации (и, надо отметить, имеют немалую константу, скрытую в асимптотике).

В качестве компромисса можно использовать структуры данных, позволяющие выполнять оба типа операций (фактически, это извлечение минимума и обновление элемента) за O(\log n). Тогда время работы алгоритма Дейкстры составит:

 O(n \log n + m \log n) = O (m \log n) 

В качестве такой структуры данных программистам на C++ удобно взять стандартный контейнер \rm set или \rm priority\_queue. Первый основан на красно-чёрном дереве, второй — на бинарной куче. Поэтому \rm priority\_queue имеет меньшую константу, скрытую в асимпотике, однако у него есть и недостаток: он не поддерживает операцию удаления элемента, из-за чего приходится делать "обходной манёвр", который фактически приводит к замене в асимптотике \log n на \log m (с точки зрения асимптотики это на самом деле ничего не меняет, но скрытую константу увеличивает).

Реализация
set
Начнём с контейнера \rm set. Поскольку в контейнере нам надо хранить вершины, упорядоченные по их величинам d[], то удобно в контейнер помещать пары: первый элемент пары — расстояние, а второй — номер вершины. В результате в \rm set будут храниться пары, автоматически упорядоченные по расстояниям, что нам и нужно.

const int INF = 1000000000;
 
int main() {
	int n;
	... чтение n ...
	vector < vector < pair<int,int> > > g (n);
	... чтение графа ...
	int s = ...; // стартовая вершина
 
	vector<int> d (n, INF),  p (n);
	d[s] = 0;
	set < pair<int,int> > q;
	q.insert (make_pair (d[s], s));
	while (!q.empty()) {
		int v = q.begin()->second;
		q.erase (q.begin());
 
		for (size_t j=0; j<g[v].size(); ++j) {
			int to = g[v][j].first,
				len = g[v][j].second;
			if (d[v] + len < d[to]) {
				q.erase (make_pair (d[to], to));
				d[to] = d[v] + len;
				p[to] = v;
				q.insert (make_pair (d[to], to));
			}
		}
	}
}
В отличие от обычного алгоритма Дейкстры, становится ненужным массив u[]. Его роль, как и функцию нахождения вершины с наименьшим расстоянием, выполняет \rm set. Изначально в него помещаем стартовую вершину s с её расстоянием. Основной цикл алгоритма выполняется, пока в очереди есть хоть одна вершина. Из очереди извлекается вершина с наименьшим расстоянием, и затем из неё выполняются релаксации. Перед выполнением каждой успешной релаксации мы сначала удаляем из \rm set старую пару, а затем, после выполнения релаксации, добавляем обратно новую пару (с новым расстоянием d[to]).

priority_queue
Принципиально здесь отличий от \rm set нет, за исключением того момента, что удалять из \rm priority\_queue произвольные элементы невозможно (хотя теоретически кучи поддерживают такую операцию, в стандартной библиотеке она не реализована). Поэтому приходится совершать "обходной манёвр": при релаксации просто не будем удалять старые пары из очереди. В результате в очереди могут находиться одновременно несколько пар для одной и той же вершины (но с разными расстояниями). Среди этих пар нас интересует только одна, для которой элемент \rm first равен d[v], а все остальные являются фиктивными. Поэтому надо сделать небольшую модификацию: в начале каждой итерации, когда мы извлекаем из очереди очередную пару, будем проверять, фиктивная она или нет (для этого достаточно сравнить \rm first и d[v]). Следует отметить, что это важная модификация: если не сделать её, то это приведёт к значительному ухудшению асимптотики (до O(nm)).

Ещё нужно помнить о том, что \rm priority\_queue упорядочивает элементы по убыванию, а не по возрастанию, как обычно. Проще всего преодолеть эту особенность не указанием своего оператора сравнения, а просто помещая в качестве элементов \rm first расстояния со знаком минус. В результате в корне кучи будут оказываться элементы с наименьшим расстоянием, что нам и нужно.

const int INF = 1000000000;
 
int main() {
	int n;
	... чтение n ...
	vector < vector < pair<int,int> > > g (n);
	... чтение графа ...
	int s = ...; // стартовая вершина
 
	vector<int> d (n, INF),  p (n);
	d[s] = 0;
	priority_queue < pair<int,int> > q;
	q.push (make_pair (0, s));
	while (!q.empty()) {
		int v = q.top().second,  cur_d = -q.top().first;
		q.pop();
		if (cur_d > d[v])  continue;
 
		for (size_t j=0; j<g[v].size(); ++j) {
			int to = g[v][j].first,
				len = g[v][j].second;
			if (d[v] + len < d[to]) {
				d[to] = d[v] + len;
				p[to] = v;
				q.push (make_pair (-d[to], to));
			}
		}
	}
}
Как правило, на практике версия с \rm priority\_queue оказывается несколько быстрее версии с \rm set.

Избавление от pair
Можно ещё немного улучшить производительность, если в контейнерах всё же хранить не пары, а только номера вершин. При этом, понятно, надо перегрузить оператор сравнения для вершин: сравнивать две вершины надо по расстояниям до них d[].

Поскольку в результате релаксации величина расстояния до какой-то вершины меняется, то надо понимать, что "сама по себе" структура данных не перестроится. Поэтому, хотя может показаться, что удалять/добавлять элементы в контейнер в процессе релаксации не надо, это приведёт к разрушению структуры данных. По-прежнему перед релаксацией надо удалить из структуры данных вершину \rm to, а после релаксации вставить её обратно — тогда никакие соотношения между элементами структуры данных не нарушатся.

А поскольку удалять элементы можно из \rm set, но нельзя из \rm priority\_queue, то получается, что этот приём применим только к \rm set. На практике он заметно увеличивает производительность, особенно когда для хранения расстояний используются большие типы данных (как \rm long\ long или \rm double).

---

### Задача

Дан граф $G=(V, E)$ (возможно, ориентированный), все рёбра которого
имеют неотрицательный вес. В $G$ выделена вершина $s$ и нужно найти
кратчайшие расстояния от $s$ до всех вершин в графе.

### Лемма

Разобьём $|V|$ на $2$ множества: $visited$ $\~-$ содержащее $start$
$\~-$ и $V \\setminus visited$. Пусть для всех вершин в $visited$ мы уже
посчитали кратчайшие расстояния. Рассмотрим среди вершин из $V
\\setminus visited$ только те, которые соединены ребром хотя бы с одной
из вершин $visited$. Теперь выберем из оставшихся вершин в $V
\\setminus visited$ такую $u$, для которой величина, равная $\\min_{v,
v \\in In(u)} \\rho (s, v) + w(v, u)$ минимальна. Тогда для $u$ верно,
что $\\rho(s, u) = \\min_{v, v \\in In(u)} \\rho (s, v) + w(v, u)$.

#### Доказательство

Пусть не так. Тогда существует путь из $s$ в $u$, длина которого меньше
описанной выше величины. Рассмотрим первое ребро на этом пути, начало
которого ($v'$) лежит в $visited$, а конец ($u'$) $\~-$ нет. Заметим
тогда, что путь от $s$ до $u'$ заведомо не длиннее пути $s \~- v' - u'
\~- u$, который, в свою очередь, по предположению от противного, короче
пути, который рассматривается в лемме (берём для $u$ вершину $v$ и
$visited$, для которой $\\rho (s, v) + w(v, u)$ минимально). Но тогда
вершина $u$ не минимальна в том смысле, в которой заявляется в лемме
$\~-$ мы нашли вершину $u'$ не из $visited$ и смежную с ней $v'$ из
$visited$, для которых расстояние $s \~- v' - u'$ меньше, чем такое же
для $u$. Противоречие.

### Описание алгоритма

  - В начале $dist\[s\] = 0$, $dist\[ V \\setminus \\{s\\}\] = INF$
  - На каждом шаге алгоритма мы выбираем из ещё не рассмотренных вершин
    минимальную в смысле леммы выше. Для этого мы, добавляя в $visited$
    очередную вершину, просматриваем всех её соседей и улучшаем для
    каждого из них оценку сверху на длину кратчайшего пути
  - Заканчиваем алгоритм мы через |V| итераций.

### Как брать минимальную вершину?

Это можно делать двумя способами:

1.  Каждый раз заново перебирать все вершины и брать минимальную. В
    таком случае сложность алгоритма становится
    $O(\\underbrace{V^2}_\\text{на каждой из V итераций рассматриваем
    все вершины} + \\underbrace{E}_\\text{суммарно на всех шагах мы
    рассмотрим каждое ребро по 2 раза})$.
2.  Поддерживать отсортированный список пар (например, с помощью
    std::set) вида (dist\[v\], v), где в dist\[v\] хранится текущая
    оценка сверху на минимальное расстояние. В этом случае
    сложность алгоритма будет
    $O(\\underbrace{ElogV}_\\text{суммарно на всех шагах мы
    прорелаксируем все рёбра} + \\underbrace{VlogV}_\\text{на
    каждой итерации мы извлекаем вершину из set'а}) = O((V+E)logV)$

### Реализация

#### За $V^2 + E$

``` C++
typedef int Vertex;
typedef long long dist_t;

vector<dist_t>
ShortestDistancesDijkstra(vector<vector<int> >& adjacent, /* граф, хранимый списками смежности */
                                         Vertex start) {
  int n = adjacent.size();
  vector<dist_t> dist(n, INF);
  dist[start] = 0LL;

  vector<bool> is_visited(n, false);

  for (int iter_n = 0; iter_n < n; ++iter_n) {
    // ============== Выбираем ближайшую непосещённую ==============

    Vertex closest_not_visited = -1;
    dist_t closest_dist = INF;

    for (Vertex v = 0; v < n; ++v) {
      if (!is_visited[v] && dist[v] < closest_dist) {
        closest_dist = dist[v];
        closest_not_visited = v;
      }
    }

    is_visited[closest_not_visited] = true;

    // ============== Релаксируем рёбра, идущие из неё ==============

    for (auto&& [to, w] : adjacent[closest_not_visited]) {
      dist[to] = min(dist[to], dist[closest_not_visited] + w;
    }
  }

  return dist;
}
```

#### За $(E+V)logV$

``` C++
typedef int Vertex;
typedef long long dist_t;

vector<dist_t>
ShortestDistancesDijkstra(vector<vector<int> >& adjacent, /* граф, хранимый списками смежности */
                                         Vertex start) {
  int n = adjacent.size();
  vector<dist_t> dist(n, INF);
  dist[start] = 0LL;

  set<pair<dist_t        /* dist[v] */,
           Vertex        /* v */ >
     > not_visited_dist;

  for (Vertex v = 0; v < n; ++v) {
    not_visited.insert({dist[v], v});
  }

  while (!not_visited_dist.empty()) {
    // ============== Выбираем ближайшую непосещённую ==============

    auto&& [closest_d, closest_not_visited] = *not_visited_dist.begin();
    not_visited_dist.erase(begin);

    // ============== Релаксация рёбер из неё ==============

    for (auto&& [to, w] : adjacent[closest_not_visited]) {
      if (dist[to] > dist[closest_not_visited] + w) {
        not_visited_dist.erase({dist[to], to});
        dist[to] = dist[closest_v] + w;
        not_visited_dist.insert({dist[to], to});
      }
    }
  }

  return dist;
}
```
